COMMENT:
Perhaps
students
with
extreme
views
are
more
likely
to
comment
thus
skewing
the
results.
However,
students
with
poor
professors
are
probably
more
likely
to
have
extreme
views.
There
is
strength
in
numbers.
If
a
professor
has
50
vitriolic
comments
on
Rate
My
Professor
(RMP),
there
is
probably
something
wrong
with
the
professor
and
not
with
the
commenters'
extreme
bias.
If
you
are
adventurous
you
can
cite
the
AAUP
research
and
ignore
the
warnings
from
the
commenters
on
RMP
and
register
for
the
class,
but
you
will
probably
regret
it.
Having
read
many
RMP
reviews,
I
would
say
that
the
majority
of
comments
are
not
in
the
realm
of
extreme,
making
it
easy
to
filter.
I
am
not
saying
RMP
is
flawless
though.
You
can't
just
rely
on
the
numerical
rating.
You
need
to
read
the
reviews
discerningly
and
with
an
analytic
approach.
Also
the
professor
needs
to
have
enough
ratings
and
comments
for
you
to
analyze
and
draw
your
own
conclusion.
Perhaps
comments
at
some
schools
could
be
more
biased
than
others.
However,
in
my
own
personal
experience,
RMP
has
been
spot
on
every
time
if
the
professor
has
enough
comments
and
if
you
read
them
carefully.
I
agree
though
that
RMP
should
not
be
used
for
official
evaluations,
but
it
could
be
used
as
a
tipoff
for
evaluators
to
take
a
closer
look
at
some
professors'
performance.
Being
an
academic
though
is
not
all
about
teaching.
It
is
also
about
creating
knowledge.
Some
academics
might
be
great
thinkers,
but
poor
teachers.
There
needs
to
be
a
room
for
both.
<EOS>
Teacher
Evaluations
Could
Be
Hurting
Faculty
Diversity
at
Universities
.
<EOS>
Recent
college
student
protests
calling
for
increased
faculty
diversity
left
people
wondering
why
there
aren'
t
more
fulltime
faculty
of
color
in
our
universities
.
<EOS>
One
reason
may
be
that
faculty
of
color
are
not
retained
at
the
same
rate
as
their
white
counterparts
,
and
bias
in
student
teaching
evaluations
could
be
contributing
to
that
disparity
.
<EOS>
A
public
example
of
student
evaluation
of
college
teaching
can
be
found
on
Rate
My
Professors
.
<EOS>
The
problem
with
such
evaluative
tools
,
according
to
research
by
the
American
Association
of
University
Professors
,
is
that
students
with
extreme
views
are
more
likely
to
complete
an
evaluation
of
a
teacher
.
<EOS>
In
these
instances
,
the
``
sample
''
of
students
surveyed
about
the
professor
's
performance
is
skewed
,
tainting
the
validity
of
the
findings
.
<EOS>
Using
student
evaluations
for
promotion
and
retention
decisions
without
supplemental
data
is
also
troubling
in
light
of
research
finding
that
when
whites
rate
the
performance
of
a
person
of
color
for
the
purposes
of
giving
feedback
to
a
third
party
,
they
consistently
rate
the
person
of
color
lower
than
the
white
person
.
<EOS>
Conversely
,
when
whites
evaluate
a
person
of
color
for
purposes
of
giving
feedback
to
that
person
directly
,
the
person
of
color
being
evaluated
actually
receives
more
favorable
marks
than
the
white
person
being
evaluated
.
<EOS>
What
's
more
,
in
Deborah
Rhode
's
fascinating
book
,
``
The
Beauty
Bias
,
''
we
learn
that
evaluators
are
more
likely
to
rate
physically
attractive
performers
more
favorably
than
those
deemed
unattractive
,
and
that
people
with
strong
African
physical
features
are
deemed
less
attractive
than
those
without
such
features
.
<EOS>
With
all
of
this
bias
in
student
evaluations
,
we
should
be
cautious
in
using
them
to
make
employment
decisions
.
<EOS>
As
the
consumers
of
higher
education
,
student
voices
are
important
.
<EOS>
But
using
student
evaluations
to
make
employment
retention
decisions
may
be
allowing
hidden
bias
to
frustrate
efforts
to
diversify
our
faculties
.
<EOS>
